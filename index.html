<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Journey | Âº∫ÂåñÂ≠¶‰π†‰πãÊóÖ</title>
    <link rel="stylesheet" href="css/styles.css">
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="container">
            <h1>üéØ Reinforcement Learning Journey</h1>
            <p class="subtitle">A systematic exploration of RL algorithms with interactive demos</p>
            <p class="author">Built with curiosity, math, and physics intuition</p>
        </div>
    </header>

    <main class="container">
        <section class="intro">
            <h2>About This Project</h2>
            <p>
                This is an interactive learning platform where I document my journey of mastering
                Reinforcement Learning. Each algorithm combines theoretical understanding with
                hands-on Python implementations that run directly in your browser.
            </p>
            <div class="tech-stack">
                <span class="tech-badge">PyScript</span>
                <span class="tech-badge">Prism.js</span>
                <span class="tech-badge">Interactive Demos</span>
            </div>
        </section>

        <section class="algorithms">
            <h2>üìö Algorithm Collection</h2>
            <div class="algorithm-grid">
                <!-- Multi-Armed Bandit -->
                <div class="algorithm-card">
                    <div class="card-header">
                        <h3>Multi-Armed Bandit</h3>
                        <span class="badge">Completed</span>
                    </div>
                    <p class="card-description">
                        The foundation of exploration vs. exploitation tradeoff.
                        Implements Œµ-greedy, UCB, and Thompson Sampling strategies.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Exploration</span>
                        <span class="topic">Exploitation</span>
                        <span class="topic">Regret</span>
                    </div>
                    <a href="algorithms/multi-armed-bandit/index.html" class="card-link">
                        Explore Algorithm ‚Üí
                    </a>
                </div>

                <!-- Contextual Bandits -->
                <div class="algorithm-card">
                    <div class="card-header">
                        <h3>Contextual Bandits</h3>
                        <span class="badge">Completed</span>
                    </div>
                    <p class="card-description">
                        Linear contextual bandits with LinUCB and LinTS algorithms.
                        Learn optimal actions based on context features using ridge regression.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Context</span>
                        <span class="topic">LinUCB</span>
                        <span class="topic">LinTS</span>
                    </div>
                    <a href="algorithms/contextual-bandits/index.html" class="card-link">
                        Explore Algorithm ‚Üí
                    </a>
                </div>

                <!-- Q-Learning -->
                <div class="algorithm-card">
                    <div class="card-header">
                        <h3>Q-Learning</h3>
                        <span class="badge">Completed</span>
                    </div>
                    <p class="card-description">
                        Temporal Difference learning for value-based methods.
                        Classic tabular RL algorithm with Bellman optimality and off-policy learning.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Bellman Equation</span>
                        <span class="topic">TD Learning</span>
                        <span class="topic">Off-Policy</span>
                    </div>
                    <a href="algorithms/q-learning/index.html" class="card-link">
                        Explore Algorithm ‚Üí
                    </a>
                </div>

                <!-- SARSA -->
                <div class="algorithm-card">
                    <div class="card-header">
                        <h3>SARSA</h3>
                        <span class="badge">Completed</span>
                    </div>
                    <p class="card-description">
                        On-policy TD control algorithm. Learns the value of actions actually taken,
                        leading to safer policies during exploration.
                    </p>
                    <div class="card-topics">
                        <span class="topic">On-Policy</span>
                        <span class="topic">TD Control</span>
                        <span class="topic">Expected SARSA</span>
                    </div>
                    <a href="algorithms/sarsa/index.html" class="card-link">
                        Explore Algorithm ‚Üí
                    </a>
                </div>

                <!-- Policy Gradient (Coming Soon) -->
                <div class="algorithm-card coming-soon">
                    <div class="card-header">
                        <h3>Policy Gradient</h3>
                        <span class="badge soon">Coming Soon</span>
                    </div>
                    <p class="card-description">
                        Direct policy optimization using gradient ascent. Foundation of modern RL.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Policy-based</span>
                        <span class="topic">REINFORCE</span>
                    </div>
                </div>

                <!-- DQN (Coming Soon) -->
                <div class="algorithm-card coming-soon">
                    <div class="card-header">
                        <h3>Deep Q-Network (DQN)</h3>
                        <span class="badge soon">Coming Soon</span>
                    </div>
                    <p class="card-description">
                        Combining Q-Learning with deep neural networks. The breakthrough that started deep RL.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Deep Learning</span>
                        <span class="topic">Experience Replay</span>
                    </div>
                </div>

                <!-- Actor-Critic (Coming Soon) -->
                <div class="algorithm-card coming-soon">
                    <div class="card-header">
                        <h3>Actor-Critic</h3>
                        <span class="badge soon">Coming Soon</span>
                    </div>
                    <p class="card-description">
                        Combining value-based and policy-based methods for stable learning.
                    </p>
                    <div class="card-topics">
                        <span class="topic">Hybrid</span>
                        <span class="topic">Advantage</span>
                    </div>
                </div>
            </div>
        </section>

        <section class="learning-notes">
            <h2>üí° Learning Philosophy</h2>
            <div class="philosophy-grid">
                <div class="philosophy-item">
                    <h3>üßÆ Mathematical Rigor</h3>
                    <p>Building intuition from first principles using math and physics background</p>
                </div>
                <div class="philosophy-item">
                    <h3>üî¨ Hands-on Experimentation</h3>
                    <p>Every algorithm comes with interactive code you can modify and test</p>
                </div>
                <div class="philosophy-item">
                    <h3>ü§î Question-Driven</h3>
                    <p>Learning through asking deep questions and exploring answers</p>
                </div>
                <div class="philosophy-item">
                    <h3>ü§ù AI-Assisted</h3>
                    <p>Leveraging AI tools to accelerate understanding and implementation</p>
                </div>
            </div>
        </section>
    </main>

    <footer>
        <div class="container">
            <p>
                Built with ‚ù§Ô∏è using PyScript, Prism.js, and curiosity |
                <a href="https://github.com/yourusername/Reinforcement-Learning" target="_blank">View on GitHub</a>
            </p>
            <p class="footer-note">
                This project documents my journey from understanding to mastery in Reinforcement Learning
            </p>
        </div>
    </footer>

    <script src="js/main.js"></script>
</body>
</html>
